config:
  # Random seed.
  seed: 1

  # Shape we want for our moving images [width, height]
  shape: [60, 50]

  # Number of frames in a particular movement/animation/gif
  num_frames: 20

  # Number of movement/animations/gifs/sequences to generate
  num_sequences: 4

  # Digits per movement/animation/gif/sequence.
  digits_per_image: 4

  # Boolean, used to decide if downloading/generating train set or test set
  training: True

  # Where to store the output
  dest: "./out"

  # Filetype for the generated image data: currently only "jpg"
  filetype: "jpg"

  labels:
    # Label type to produce: "coco" or "mots"
    # Use "coco" to train a detector (e.g. Mask R-CNN) like they were still images (it is still a sequence but each image is treaded independently)
    # Use "mots" to train a whole segmentation and tracking pipeline (includes track ids)
    labeltype: "coco"

    # Only relevant if labeltype == "coco".
    # Some detectors expect masks encoded as polygons (e.g. detectron2).
    # Others can work with RLE masks (specification see here: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/mask.py)
    # The formats are mixed in the original coco dataset.
    # Can be "polygon" or "rle"
    masktype: "rle"

  # Controls how much the size of a digit can change. <1 for lower bound, >1 for upper bound. 1 for the original size
  size_band: [0.7, 1.3]

  # Controls how fast the size changes. Should be [0, 1]. 0 for no change, 1 for rapid change.
  size_change: 0.05

  # Highest and lowest bound for the random brightness of each digit
  brightness_band: [0.2, 1]

  # Delta brightness change. This controls how fast the brightness changes from frame to frame.
  # Should be in [0, 1], 0 for no change, 1 for a rapid change
  brightness_change: 0.05

  # Threshold for creating segmentation mask out of the original digit image.
  # The lower it is, the thicker the mask and the less gaps it has. This is a raw
  # grayscale pixel value, so should be between in [0, 255].
  seg_threshold: 50